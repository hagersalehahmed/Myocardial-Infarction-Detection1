{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CETtDDAAETDH"
   },
   "outputs": [],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjZSolvm8K25"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder() \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from kerastuner import HyperModel\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Dropout, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Embedding, Add\n",
    "\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation,GlobalMaxPooling1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlzBnQ_z8PAU"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5zlMlH-QjFz"
   },
   "source": [
    "## Read training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqNfvg4O8K3B"
   },
   "outputs": [],
   "source": [
    "#read train dataset\n",
    "train=  pd.read_csv('/content/drive/MyDrive/Myocardial Infarction Detection/ptbdb/train.csv',encoding='utf-8')\n",
    "test= pd.read_csv('/content/drive/MyDrive/Myocardial Infarction Detection/ptbdb/test.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3lzncG8clbX"
   },
   "outputs": [],
   "source": [
    "train.iloc[: , -1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZ7Ee4XGglbk"
   },
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Xd6cfsIQ1eS"
   },
   "source": [
    "## convert label to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ufs4Y3mIdU3"
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "X_train, y_train = train.iloc[: , :-1], train.iloc[: , -1]\n",
    "\n",
    "\n",
    "X_test, y_test = test.iloc[: , :-1], test.iloc[: , -1]\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tusq7R1v8K3G"
   },
   "outputs": [],
   "source": [
    "print(\"X shape=\" +str(X_train.shape))\n",
    "print(\"y shape=\" +str(y_train.shape))\n",
    "\n",
    "print(\"testX shape=\" +str(X_test.shape))\n",
    "print(\"testy shape=\" +str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZlo8IktUIXx"
   },
   "source": [
    "## Define some of function that are used as matixs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-1WP2Ta8K3K"
   },
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HslHUgQJUgJD"
   },
   "source": [
    "## Optimize and build mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MD_KMEJaj1_L"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  \n",
    "\n",
    "    dropout_min  =  .1\n",
    "    dropout_max  =  0.9\n",
    "    dropout_step =  0.1\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(\n",
    "        Conv1D(\n",
    "            filters=hp.Choice(\n",
    "                'num_filters1',[16,128] ),input_shape=(187,1), activation='relu', kernel_size=hp.Choice('kernel_size1', [4,5])))\n",
    " \n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=hp.Choice('Pool_Size1', [2])))\n",
    "\n",
    "    model.add(Dropout(rate=hp.Float('dropout1', min_value=dropout_min, max_value=dropout_max , default=dropout_step)))\n",
    "\n",
    "   \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(layers.Dense(units=hp.Int('unit1',  min_value=20,\n",
    "                                                 max_value=500,\n",
    "                                                 step=20),activation = 'relu', \n",
    "                          ))\n",
    "    \n",
    "\n",
    "    model.add(layers.Dense(units=hp.Int('unit2',  min_value=20,\n",
    "                                                 max_value=400,\n",
    "                                                 step=20),activation = 'relu'))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam( hp.Float('learning_rate',min_value=1e-4,max_value=1e-2)),loss='categorical_crossentropy', metrics=['acc',f1_m,precision_m, recall_m] )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRz18OoBkn_p"
   },
   "outputs": [],
   "source": [
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_acc',\n",
    "    max_trials=1,\n",
    "    project_name='/content/drive/MyDrive/Myocardial Infarction Detection/ptbdb/CNN_Layer1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ll88A6wkkzq5"
   },
   "outputs": [],
   "source": [
    "epoch=20\n",
    "BATCH_SIZE=1000\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=30, verbose=1)\n",
    "callback_list = [ early_stopping ]\n",
    "\n",
    "# split training data into stratified train/dev sets\n",
    "\n",
    "h=tuner.search(X_train, y_train,\n",
    "             epochs=epoch,\n",
    "             batch_size=BATCH_SIZE, \n",
    "             callbacks=callback_list, validation_data=((X_test, y_test)) )\n",
    "            \n",
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4g_kfVYAq1WD"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/Myocardial Infarction Detection/ptbdb/model/CNN_Layer1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imOLWgZYq_0i"
   },
   "outputs": [],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cwHnZUtregw"
   },
   "outputs": [],
   "source": [
    "history=model.fit(X_train, y_train,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=epoch, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hu6Q75oAsEz8"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zug6lEb4sJJS"
   },
   "source": [
    "## Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZ85jUmqQYRx"
   },
   "outputs": [],
   "source": [
    "AccuracyTest=[]\n",
    "PrecisionTest=[]\n",
    "RecallTest=[]\n",
    "F1Test=[]\n",
    "y_true=[]\n",
    "for element in y_test:\n",
    "  y_true.append(np.argmax(element))\n",
    "for i in range(0,1): \n",
    "    prediction_proba=model.predict(X_test)\n",
    "    y_pred=np.argmax(prediction_proba,axis=1)\n",
    "\n",
    "    Accurcy_Test= accuracy_score(y_true,y_pred)\n",
    "    Precision_Test=precision_score(y_true, y_pred,average='weighted')\n",
    "\n",
    "    Recall_Test=recall_score(y_true, y_pred, average='weighted')\n",
    "    F1_Test=f1_score(y_true, y_pred, average='weighted') \n",
    "\n",
    "    AccuracyTest.append(round(100*Accurcy_Test, 2))\n",
    "    PrecisionTest.append(round(100*Precision_Test, 2))\n",
    "    RecallTest.append(round(100*Recall_Test, 2))\n",
    "    F1Test.append(round(100*F1_Test, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k25fKcEyvQ3q"
   },
   "outputs": [],
   "source": [
    "ReultofTest=pd.DataFrame([])\n",
    "ReultofTest=ReultofTest.append({'AccuracyTest' : round(np.mean(AccuracyTest),2),'PrecisionTest':round(np.mean(PrecisionTest),2),\n",
    "             'RecallTest' : round(np.mean(RecallTest),2),'F1Test':round(np.mean(F1Test),2)}, ignore_index=True)\n",
    "\n",
    "ReultofTest.reindex(['AccuracyTest','PrecisionTest','RecallTest','F1Test'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZJlozBKBIK3"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=['Normal','Abnormal']))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
